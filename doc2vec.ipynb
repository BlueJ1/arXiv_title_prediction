{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:00:14.813507Z",
     "end_time": "2023-05-28T16:00:14.839060Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_csv(filename, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:04:39.447392Z",
     "end_time": "2023-05-28T16:04:39.480305Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "df = load_data(\"data_chunks/chunk_1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:32:06.602005Z",
     "end_time": "2023-05-28T16:32:06.745618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              title   \n0           0  A determinant of Stirling cycle numbers counts...  \\\n1           1  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n2           2  Polymer Quantum Mechanics and its Continuum Limit   \n3           3  The Spitzer c2d Survey of Large, Nearby, Inste...   \n4           4  Computing genus 2 Hilbert-Siegel modular forms...   \n\n                                            abstract  \n0    We show that a determinant of Stirling cycle...  \n1    In this paper we show how to compute the $\\L...  \n2    A rather non-standard quantum representation...  \n3    We discuss the results from the combined IRA...  \n4    In this paper we present an algorithm for co...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A determinant of Stirling cycle numbers counts...</td>\n      <td>We show that a determinant of Stirling cycle...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n      <td>In this paper we show how to compute the $\\L...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n      <td>A rather non-standard quantum representation...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n      <td>We discuss the results from the combined IRA...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Computing genus 2 Hilbert-Siegel modular forms...</td>\n      <td>In this paper we present an algorithm for co...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:04:43.373771Z",
     "end_time": "2023-05-28T16:04:43.446574Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def clean_data(doc):\n",
    "# make all characters lowercase\n",
    "    doc = doc.lower();\n",
    "    for char in string.punctuation:\n",
    "        doc = doc.replace(char, ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    doc = \" \".join(tokens)\n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T11:24:19.100599Z",
     "end_time": "2023-05-28T11:24:19.111568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def clean_text (text):\n",
    "    cleaned_reviews = []\n",
    "    for doc in text:\n",
    "        clean = clean_data(doc)\n",
    "        cleaned_reviews.append(clean)\n",
    "    return cleaned_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T11:24:26.952121Z",
     "end_time": "2023-05-28T11:24:26.961096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "df[\"cleaned_abstract\"] = clean_text(df[\"abstract\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:32:21.273554Z",
     "end_time": "2023-05-28T16:32:37.476466Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Doc2Vec Model #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def tag_data(df, dataset_counter):\n",
    "    tagged_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        paragraph = row['cleaned_abstract']\n",
    "        # Tokenize the paragraph into words\n",
    "        tags = [f\"{dataset_counter}_{index}\"]  # Unique tag combining dataset_counter and index\n",
    "        words = word_tokenize(paragraph)\n",
    "        # Create a TaggedDocument with words and an index as the tag\n",
    "        tagged_data.append(TaggedDocument(words=words, tags=tags))\n",
    "    return tagged_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:29:59.729976Z",
     "end_time": "2023-05-28T16:29:59.760893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "tagged_data = tag_data(df, 1)\n",
    "test_model = Doc2Vec(vector_size=300, window=5, min_count=1, epochs=10)\n",
    "test_model.build_vocab(tagged_data)\n",
    "test_model.train(tagged_data, total_examples=test_model.corpus_count, epochs=test_model.epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:32:37.485442Z",
     "end_time": "2023-05-28T16:33:01.118414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def test_retrieve_embeddings(df, dataset_counter):\n",
    "    paragraph_embeddings = []\n",
    "    for index, _ in df.iterrows():\n",
    "        tag = [f\"{dataset_counter}_{index}\"]\n",
    "        vector = test_model.dv[tag]\n",
    "        paragraph_embeddings.append(vector)\n",
    "    return paragraph_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T15:53:24.516252Z",
     "end_time": "2023-05-28T15:53:24.579115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "embeddings = test_retrieve_embeddings(df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:20:05.394380Z",
     "end_time": "2023-05-28T16:20:06.155847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.05853846,  0.12990786,  0.09955842,  0.01129305,  0.01371073,\n       -0.10407504,  0.00695676,  0.18072245,  0.04993944, -0.03912092,\n        0.0019877 , -0.00741177, -0.0160102 , -0.01287496, -0.06809775,\n       -0.04715111,  0.13039264, -0.11001746, -0.01203263, -0.00446862,\n       -0.1425551 , -0.06038997,  0.08392388,  0.05226517,  0.13549608,\n       -0.0167216 , -0.01507288, -0.04386185, -0.14844136, -0.13457423,\n       -0.04697548,  0.03975921, -0.05266241, -0.00127416, -0.04520372,\n        0.01356521, -0.02390807, -0.17189   , -0.01763073, -0.00558726,\n       -0.01078703, -0.07455625, -0.06139837, -0.15039201,  0.07285127,\n       -0.02163354,  0.00432912, -0.01121517, -0.05049729,  0.17521936,\n       -0.0224429 ,  0.08021046, -0.07906831,  0.00533044, -0.14926799,\n        0.10100345,  0.03749479, -0.02722978, -0.05376054, -0.03557311,\n       -0.09521517, -0.02923338, -0.08365134, -0.04411107,  0.12877952,\n       -0.04005622,  0.03942119, -0.03837168, -0.04304772, -0.04387997,\n       -0.09393299,  0.15987258,  0.10039897, -0.08399215,  0.00050863,\n        0.10826242, -0.08621684, -0.00825577, -0.06832725,  0.06866526,\n       -0.02637873, -0.22248857,  0.10577772,  0.18659319, -0.01722463,\n        0.04131221, -0.03151828, -0.07032254,  0.08947195,  0.06587178,\n        0.08384594, -0.06666077, -0.01972686, -0.06022071,  0.03405008,\n        0.08146685,  0.0545835 , -0.0628539 , -0.09586395,  0.09174623,\n       -0.03670493, -0.01940702,  0.14555976, -0.0273943 ,  0.02670157,\n       -0.11667788, -0.0244598 ,  0.08992133, -0.08385859,  0.06496372,\n       -0.21592388, -0.0995871 ,  0.04583587,  0.13404705,  0.07771458,\n       -0.02439832, -0.07330567,  0.04546835,  0.17017713, -0.06872021,\n        0.04985843,  0.01997276,  0.03968311, -0.05121499, -0.01610142,\n        0.00438802,  0.02957442, -0.02689877,  0.04039241,  0.00612011,\n        0.01440748,  0.17696738,  0.09307697, -0.12558393,  0.08586223,\n        0.06855846,  0.02855462, -0.12147583, -0.07112894, -0.03934092,\n        0.03875594, -0.1421511 , -0.02249673,  0.00760525,  0.03301333,\n       -0.08745962, -0.19622467, -0.00248277,  0.05843704, -0.0994798 ,\n       -0.01735815, -0.12752728, -0.09824219, -0.13144223, -0.03794197,\n       -0.02438843, -0.110866  , -0.08811596,  0.0793914 ,  0.16873191,\n       -0.03915112,  0.2322521 , -0.0235114 ,  0.14069006, -0.08240433,\n        0.05608879,  0.07678881, -0.0711762 ,  0.03520359,  0.13741927,\n       -0.01253698, -0.04367875,  0.01730095,  0.06554338,  0.01288241,\n       -0.00411404, -0.10031994, -0.14276214, -0.01189922,  0.06027963,\n       -0.07589322,  0.06337768, -0.04184541, -0.10537513,  0.00268673,\n       -0.00519929,  0.17102195,  0.11353935,  0.16208613, -0.06627472,\n        0.07056804,  0.05815095, -0.13453189,  0.09238799,  0.06044639,\n       -0.08293407,  0.06368773, -0.12728688,  0.08123193, -0.00415395,\n       -0.05145276, -0.01703573,  0.06939583, -0.06793191,  0.04719605,\n       -0.09762093, -0.07116139,  0.0626792 , -0.06096273, -0.06665944,\n       -0.0303417 , -0.05082757, -0.08517825, -0.07762467,  0.0754344 ,\n       -0.11991568,  0.02554322, -0.19719744, -0.13239314, -0.07699075,\n        0.13978247,  0.02881254, -0.06956948, -0.14378136, -0.03648715,\n       -0.02201518, -0.01492941,  0.05927465, -0.08282922,  0.07625631,\n        0.0811606 ,  0.0048279 ,  0.02481347,  0.10534094, -0.05256563,\n        0.08108205, -0.08960415,  0.02840347,  0.01457691, -0.11492669,\n        0.001988  ,  0.0039342 , -0.03711112, -0.0440784 ,  0.05793718,\n       -0.08714039,  0.04806404,  0.05783126, -0.04467058,  0.05242996,\n       -0.05872363,  0.1004479 ,  0.05308548, -0.02224   , -0.0640619 ,\n       -0.03551485,  0.01866526,  0.14141485, -0.08381495,  0.00042827,\n        0.12712292,  0.01912505, -0.02883699, -0.08726344, -0.20451182,\n       -0.04606861,  0.04676494,  0.05758445, -0.04283732, -0.01816162,\n       -0.11531895,  0.02183954, -0.0152642 , -0.06732843,  0.12836587,\n        0.03194353,  0.06925459,  0.00036614, -0.07891399,  0.00748002,\n        0.02463528,  0.04909813, -0.01938624,  0.07774225, -0.05814336,\n       -0.07276155, -0.26208895,  0.01486867,  0.01848743,  0.14594662,\n        0.03811389,  0.07202232,  0.14758293, -0.02264203,  0.10700091,\n        0.09911344, -0.01221106, -0.07120643,  0.00174881,  0.02501032],\n      dtype=float32)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-28T16:20:06.164854Z",
     "end_time": "2023-05-28T16:20:06.232640Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training on Full Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_0.csv\n",
      "chunk_1.csv\n"
     ]
    }
   ],
   "source": [
    "# training the model on all chunks in data_chunks folder\n",
    "# this needs to be changed to the right folder when data has been split to train, valid,test\n",
    "# this is taking a LONG time\n",
    "folder_path = 'data_chunks'\n",
    "model = Doc2Vec(vector_size=300, window=5, min_count=1, epochs=10)\n",
    "dataset_counter = 0\n",
    "for dataset in os.listdir(folder_path):\n",
    "    print(dataset)\n",
    "    df = load_data(folder_path+'/'+dataset)\n",
    "    df[\"cleaned_abstract\"] = clean_text(df[\"abstract\"])\n",
    "    tagged_data = tag_data(df, dataset_counter)\n",
    "    if dataset_counter == 0:\n",
    "        model.build_vocab(tagged_data)\n",
    "    else:\n",
    "        model.build_vocab(tagged_data, update=True)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    dataset_counter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrieve_embeddings(df, dataset_counter):\n",
    "    paragraph_embeddings = []\n",
    "    for index, _ in df.iterrows():\n",
    "        tag = [f\"{dataset_counter}_{index}\"]\n",
    "        vector = model.dv[tag]\n",
    "        paragraph_embeddings.append(vector)\n",
    "    return paragraph_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings = retrieve_embeddings(df, 1)\n",
    "embeddings[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
